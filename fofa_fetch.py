import os
import re
import requests
import time
import concurrent.futures

# ===============================
# é…ç½®åŒº
FOFA_URLS = {
    "https://fofa.info/result?qbase64=InVkcHh5IiAmJiBjb3VudHJ5PSJDTiI%3D": "ip.txt",
}
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}

COUNTER_FILE = "è®¡æ•°.txt"
IP_DIR = "ip"
RTP_DIR = "rtp"
ZUBO_FILE = "zubo.txt"
IPTV_FILE = "IPTV.txt"

# ===============================
# åˆ†ç±»ä¸æ˜ å°„é…ç½®
CHANNEL_CATEGORIES = {
    "å¤®è§†é¢‘é“": ["CCTV1", "CCTV2"],
    "å«è§†é¢‘é“": ["æ¹–å—å«è§†", "æµ™æ±Ÿå«è§†"],
    "æ•°å­—é¢‘é“": ["CHCåŠ¨ä½œç”µå½±", "CHCå®¶åº­å½±é™¢", "CHCå½±è¿·ç”µå½±"],
}

CHANNEL_MAPPING = {
    "CCTV1": ["CCTV-1", "CCTV-1 HD", "CCTV1 HD", "CCTV-1ç»¼åˆ", "CCTV1 4M1080", "CCTV1 5M1080HEVC"],
    "CCTV2": ["CCTV-2", "CCTV-2 HD", "CCTV2 HD", "CCTV-2è´¢ç»", "CCTV2 720", "èŠ‚ç›®æš‚æ—¶ä¸å¯ç”¨ 1080"],
    "æ¹–å—å«è§†": ["æ¹–å—", "æ¹–å—HD", "æ¹–å—å«è§†é«˜æ¸…"],
    "æµ™æ±Ÿå«è§†": ["æµ™æ±Ÿ", "æµ™æ±ŸHD", "æµ™æ±Ÿå«è§†é«˜æ¸…"],
}

# ===============================
# è®¡æ•°é€»è¾‘
def get_run_count():
    if os.path.exists(COUNTER_FILE):
        try:
            return int(open(COUNTER_FILE).read().strip())
        except:
            return 0
    return 0

def save_run_count(count):
    open(COUNTER_FILE, "w").write(str(count))

def check_and_clear_files_by_run_count():
    os.makedirs(IP_DIR, exist_ok=True)
    count = get_run_count() + 1
    if count >= 73:
        print(f"ğŸ§¹ ç¬¬ {count} æ¬¡è¿è¡Œï¼Œæ¸…ç©º {IP_DIR} ä¸‹æ‰€æœ‰ .txt æ–‡ä»¶")
        for f in os.listdir(IP_DIR):
            if f.endswith(".txt"):
                os.remove(os.path.join(IP_DIR, f))
        save_run_count(1)
        return "w", 1
    else:
        save_run_count(count)
        return "a", count

# ===============================
# IP è¿è¥å•†åˆ¤æ–­
def get_isp(ip):
    if ip.startswith(("113.", "116.", "117.", "118.", "119.")):
        return "ç”µä¿¡"
    elif ip.startswith(("36.", "39.", "42.", "43.", "58.")):
        return "è”é€š"
    elif ip.startswith(("100.", "101.", "102.", "103.", "104.", "223.")):
        return "ç§»åŠ¨"
    return "æœªçŸ¥"

# ===============================
# å·¥å…·å‡½æ•°
def normalize_channel_name(name):
    for std, aliases in CHANNEL_MAPPING.items():
        for alias in aliases:
            if alias.lower() in name.lower():
                return std
    return name.strip()

def test_url_latency(url, timeout=5):
    try:
        start = time.time()
        r = requests.get(url, timeout=timeout, stream=True)
        if r.status_code == 200:
            return time.time() - start
    except:
        return None
    return None

# ===============================
# ç¬¬ä¸€é˜¶æ®µï¼šçˆ¬å– IP
def first_stage():
    all_ips = set()
    for url, filename in FOFA_URLS.items():
        print(f"ğŸ“¡ æ­£åœ¨çˆ¬å– {filename} ...")
        try:
            r = requests.get(url, headers=HEADERS, timeout=15)
            urls_all = re.findall(r'<a href="http://(.*?)"', r.text)
            all_ips.update(u.strip() for u in urls_all)
        except Exception as e:
            print(f"âŒ çˆ¬å–å¤±è´¥ï¼š{e}")
        time.sleep(3)

    province_isp_dict = {}
    for ip_port in all_ips:
        try:
            ip = ip_port.split(":")[0]
            res = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=10)
            data = res.json()
            province = data.get("regionName", "æœªçŸ¥")
            isp = get_isp(ip)
            if isp == "æœªçŸ¥":
                continue
            fname = f"{province}{isp}.txt"
            province_isp_dict.setdefault(fname, set()).add(ip_port)
        except Exception:
            continue

    mode, run_count = check_and_clear_files_by_run_count()
    for filename, ip_set in province_isp_dict.items():
        path = os.path.join(IP_DIR, filename)
        with open(path, mode, encoding="utf-8") as f:
            for ip_port in sorted(ip_set):
                f.write(ip_port + "\n")
        print(f"{path} å·²{'è¦†ç›–' if mode=='w' else 'è¿½åŠ '}å†™å…¥ {len(ip_set)} ä¸ª IP")
    print(f"âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼Œå½“å‰è½®æ¬¡ï¼š{run_count}")
    return run_count

# ===============================
# ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆå¹¶æ¨é€ zubo.txt
def second_stage():
    print("ğŸ”” ç¬¬äºŒé˜¶æ®µè§¦å‘ï¼šç”Ÿæˆ zubo.txt")
    combined_lines = []
    for ip_file in os.listdir(IP_DIR):
        if not ip_file.endswith(".txt"):
            continue
        ip_path = os.path.join(IP_DIR, ip_file)
        rtp_path = os.path.join(RTP_DIR, ip_file)
        if not os.path.exists(rtp_path):
            continue

        province_operator = ip_file.replace(".txt", "")
        with open(ip_path, encoding="utf-8") as f1, open(rtp_path, encoding="utf-8") as f2:
            ip_lines = [x.strip() for x in f1 if x.strip()]
            rtp_lines = [x.strip() for x in f2 if x.strip()]

        if not ip_lines or not rtp_lines:
            continue

        # æ£€æµ‹ç¬¬ä¸€ä¸ªé¢‘é“å¯ç”¨æ€§
        first_rtp_line = rtp_lines[0]
        if "," not in first_rtp_line:
            continue
        ch_name, rtp_url = first_rtp_line.split(",", 1)

        def build_and_check(ip_port):
            url = f"http://{ip_port}/rtp/{rtp_url.split('rtp://')[1]}"
            try:
                r = requests.get(url, timeout=5, stream=True)
                if r.status_code == 200:
                    return ip_port
            except:
                return None
            return None

        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as exe:
            valid_ips = [ip for ip in exe.map(build_and_check, ip_lines) if ip]

        for ip_port in valid_ips:
            for rtp_line in rtp_lines:
                if "," not in rtp_line:
                    continue
                ch_name, rtp_url = rtp_line.split(",", 1)
                combined_lines.append(f"{ch_name},http://{ip_port}/rtp/{rtp_url.split('rtp://')[1]}")

    # å»é‡
    unique = {}
    for line in combined_lines:
        url_part = line.split(",", 1)[1]
        if url_part not in unique:
            unique[url_part] = line

    # å†™å…¥ zubo.txt å¹¶æ¨é€
    with open(ZUBO_FILE, "w", encoding="utf-8") as f:
        for line in unique.values():
            f.write(line + "\n")
    print(f"ğŸ¯ ç¬¬äºŒé˜¶æ®µå®Œæˆï¼Œzubo.txt å…± {len(unique)} æ¡ URL")

    os.system('git config --global user.name "github-actions"')
    os.system('git config --global user.email "github-actions@users.noreply.github.com"')
    os.system("git add zubo.txt")
    os.system('git commit -m "è‡ªåŠ¨æ›´æ–° zubo.txt" || echo "âš ï¸ æ— éœ€æäº¤"')
    os.system("git push origin main")
    return unique

# ===============================
# ç¬¬ä¸‰é˜¶æ®µï¼šä¸¥æ ¼æ£€æµ‹ä»£è¡¨é¢‘é“ï¼Œç”Ÿæˆ IPTV.txt
def third_stage():
    print("ğŸ§© ç¬¬ä¸‰é˜¶æ®µå¼€å§‹ï¼šæ£€æµ‹ä»£è¡¨é¢‘é“å¹¶åˆ†ç±»ç”Ÿæˆ IPTV.txt")
    if not os.path.exists(ZUBO_FILE):
        print("âš ï¸ æœªæ‰¾åˆ° zubo.txtï¼Œè·³è¿‡ç¬¬ä¸‰é˜¶æ®µ")
        return

    with open(ZUBO_FILE, encoding="utf-8") as f:
        lines = [x.strip() for x in f if x.strip()]

    # å»ºç«‹é¢‘é“æ˜ å°„åæŸ¥è¡¨
    reverse_map = {}
    for std, aliases in CHANNEL_MAPPING.items():
        for name in aliases:
            reverse_map[name] = std

    # æ˜ å°„æ ‡å‡†é¢‘é“å
    mapped_lines = []
    for line in lines:
        if "," not in line:
            continue
        ch_name, url = line.split(",", 1)
        ch_std = reverse_map.get(ch_name, ch_name)
        mapped_lines.append((ch_std, url))

    # åˆ†ç»„ï¼šæŒ‰ IP å½’ç±»
    ip_groups = {}
    for ch, url in mapped_lines:
        ip_match = re.search(r"http://(.*?)/", url)
        if ip_match:
            ip = ip_match.group(1)
            ip_groups.setdefault(ip, []).append((ch, url))

    # ä»£è¡¨é¢‘é“æ£€æµ‹å‡½æ•°
    def is_playable(url, timeout=5):
        try:
            r = requests.get(url.split("$")[0], timeout=timeout, stream=True)
            return r.status_code == 200
        except:
            return False

    valid_lines = []
    for ip, entries in ip_groups.items():
        # ä¼˜å…ˆæ£€æµ‹ CCTV1ï¼Œå…¶æ¬¡å¯ä»¥æ£€æµ‹æ¹–å—å«è§†
        rep_channels = [u for c, u in entries if c == "CCTV1"]
        if not rep_channels:
            rep_channels = [u for c, u in entries if c == "æ¹–å—å«è§†"]
        if not rep_channels:
            continue  # æ²¡æœ‰ä»£è¡¨é¢‘é“ï¼Œç›´æ¥ä¸¢å¼ƒ

        # æ£€æµ‹ä»£è¡¨é¢‘é“æ˜¯å¦å¯æ’­
        if any(is_playable(u) for u in rep_channels):
            # ä»£è¡¨é¢‘é“å¯æ’­ï¼Œä¿ç•™æ•´ç»„ IP
            valid_lines.extend([f"{c},{u}" for c, u in entries])
        else:
            print(f"ğŸš« {ip} ä»£è¡¨é¢‘é“ä¸å¯æ’­ï¼Œä¸¢å¼ƒæ•´ç»„ IP")

    # åˆ†ç±»æ’åºè¾“å‡º
    ordered_lines = []
    for category, names in CHANNEL_CATEGORIES.items():
        ordered_lines.append(f"{category},#genre#")
        for ch in names:
            for line in valid_lines:
                if line.startswith(ch + ","):
                    ordered_lines.append(line)
        ordered_lines.append("")  # åˆ†éš”

    with open(IPTV_FILE, "w", encoding="utf-8") as f:
        for line in ordered_lines:
            f.write(line + "\n")

    print(f"âœ… ç¬¬ä¸‰é˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ IPTV.txt å…± {len(valid_lines)} æ¡æœ‰æ•ˆé¢‘é“")

    # æ¨é€ IPTV.txt
    os.system('git config --global user.name "github-actions"')
    os.system('git config --global user.email "github-actions@users.noreply.github.com"')
    os.system("git add IPTV.txt")
    os.system('git commit -m "è‡ªåŠ¨æ›´æ–° IPTV.txt" || echo "âš ï¸ æ— éœ€æäº¤"')
    os.system("git push origin main")
# ===============================
# ä¸»æµç¨‹
if __name__ == "__main__":
    run_count = first_stage()
    if run_count in [12, 24, 36, 48, 60, 72]:
        zubo_data = second_stage()
        third_stage(zubo_data)