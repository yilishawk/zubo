import os
import re
import requests
import time
from datetime import datetime
import concurrent.futures

# ===============================
# é…ç½®
FOFA_URLS = {
    "https://fofa.info/result?qbase64=InVkcHh5IiAmJiBjb3VudHJ5PSJDTiI%3D": "ip.txt",
}

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/120.0.0.0 Safari/537.36"
}

COUNTER_FILE = "è®¡æ•°.txt"
IP_DIR = "ip"
RTP_DIR = "rtp"
ZUBO_FILE = "zubo.txt"

# ===============================
# è®¡æ•°ç®¡ç†
def get_run_count():
    if os.path.exists(COUNTER_FILE):
        try:
            with open(COUNTER_FILE, "r", encoding="utf-8") as f:
                return int(f.read().strip())
        except Exception:
            return 0
    return 0

def save_run_count(count):
    with open(COUNTER_FILE, "w", encoding="utf-8") as f:
        f.write(str(count))

def check_and_clear_files_by_run_count():
    """
    æ¯è¿è¡Œ19æ¬¡æ¸…ç©º IP_DIR ä¸‹æ‰€æœ‰ txt æ–‡ä»¶ã€‚
    å‰18æ¬¡è¿½åŠ ï¼Œç¬¬19æ¬¡æ¸…ç©ºè¦†ç›–ã€‚
    è¿”å›å†™å…¥æ¨¡å¼ w æˆ– a
    """
    os.makedirs(IP_DIR, exist_ok=True)
    count = get_run_count() + 1
    if count >= 19:
        print(f"ğŸ§¹ ç¬¬ {count} æ¬¡è¿è¡Œï¼Œæ¸…ç©º {IP_DIR} ä¸‹æ‰€æœ‰ .txt æ–‡ä»¶...")
        for file in os.listdir(IP_DIR):
            if file.endswith(".txt"):
                os.remove(os.path.join(IP_DIR, file))
                print(f"å·²åˆ é™¤ï¼š{file}")
        save_run_count(1)  # æ¸…ç©ºåè®¡æ•°ä»1å¼€å§‹
        return "w", 1
    else:
        print(f"â° å½“å‰ç¬¬ {count} æ¬¡è¿è¡Œï¼Œæœ¬æ¬¡æ‰§è¡Œä¸ºè¿½åŠ æ¨¡å¼")
        save_run_count(count)
        return "a", count

# ===============================
# IPè¿è¥å•†åˆ¤æ–­
def get_isp(ip):
    if re.match(r"^(1[0-9]{2}|2[0-3]{2}|42|43|58|59|60|61|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|175|180|182|183|184|185|186|187|188|189|223)\.", ip):
        return "ç”µä¿¡"
    elif re.match(r"^(42|43|58|59|60|61|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|175|180|182|183|184|185|186|187|188|189|223)\.", ip):
        return "è”é€š"
    elif re.match(r"^(223|36|37|38|39|100|101|102|103|104|105|106|107|108|109|134|135|136|137|138|139|150|151|152|157|158|159|170|178|182|183|184|187|188|189)\.", ip):
        return "ç§»åŠ¨"
    return "æœªçŸ¥"

# ===============================
# ç¬¬ä¸€é˜¶æ®µï¼šçˆ¬å– FOFA IP å¹¶åˆ†ç±»å†™å…¥ ip/
all_ips = set()
for url, filename in FOFA_URLS.items():
    try:
        print(f"æ­£åœ¨çˆ¬å– {filename} ...")
        resp = requests.get(url, headers=HEADERS, timeout=15)
        page_content = resp.text
        pattern = r'<a href="http://(.*?)" target="_blank">'
        urls_all = re.findall(pattern, page_content)
        for u in urls_all:
            all_ips.add(u.strip())
        print(f"{filename} çˆ¬å–å®Œæˆï¼Œå…± {len(all_ips)} ä¸ª IP")
    except Exception as e:
        print(f"çˆ¬å– {filename} å¤±è´¥ï¼š{e}")
    time.sleep(3)

province_isp_dict = {}
for ip_port in all_ips:
    try:
        ip = ip_port.split(':')[0]
        resp = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=10)
        data = resp.json()
        province = data.get("regionName", "æœªçŸ¥")
        isp_name = get_isp(ip)
        if isp_name == "æœªçŸ¥":
            continue
        fname = f"{province}{isp_name}.txt"
        if fname not in province_isp_dict:
            province_isp_dict[fname] = set()
        province_isp_dict[fname].add(ip_port)
        time.sleep(0.5)
    except Exception as e:
        print(f"{ip_port} æŸ¥è¯¢å¤±è´¥ï¼š{e}")
        continue

write_mode, run_count = check_and_clear_files_by_run_count()

for filename, ip_set in province_isp_dict.items():
    save_path = os.path.join(IP_DIR, filename)
    with open(save_path, write_mode, encoding="utf-8") as f:
        for ip_port in sorted(ip_set):
            f.write(ip_port + "\n")
    print(f"{save_path} å·²{'è¦†ç›–' if write_mode=='w' else 'è¿½åŠ '}å†™å…¥ {len(ip_set)} ä¸ª IP")

print(f"âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼Œæœ¬æ¬¡è¿è¡Œè½®æ¬¡ï¼š{run_count}")

# ===============================
# -------------------------------
# ç¬¬äºŒé˜¶æ®µï¼šæŒ‰æ–°è§„åˆ™è§¦å‘å¹¶ç”Ÿæˆ zubo.txt
# è§¦å‘ï¼šrun_count ä¸º 12ã€24ã€36ã€48ã€60ã€72 æ—¶æ‰§è¡Œç”Ÿæˆ
# é¢å¤–ï¼šå½“ run_count == 73 æ—¶ï¼Œæ¸…ç©º ip/ ä¸‹æ‰€æœ‰ txt å¹¶å°†è®¡æ•°é‡ç½®ä¸º 1ï¼ˆå¼€å§‹æ–°è½®å›ï¼‰
# æ³¨æ„ï¼šæœ¬æ®µåªè´Ÿè´£ç”Ÿæˆ zubo.txtï¼ˆè¦†ç›–ï¼‰ï¼Œä¸è´Ÿè´£ git æäº¤/æ¨é€
# -------------------------------

# éœ€è¦ concurrent.futures å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
import concurrent.futures

# è§¦å‘é›†åˆï¼ˆ12 çš„å€æ•°ï¼Œåˆ° 72ï¼‰
TRIGGERS = {12, 24, 36, 48, 60, 72}

if run_count in TRIGGERS:
    print(f"ğŸ”” ç¬¬äºŒé˜¶æ®µè§¦å‘ï¼ˆrun_count={run_count}ï¼‰ï¼šç”Ÿæˆ {ZUBO_FILE}")
    combined_lines = []

    # éå† ip/ æ–‡ä»¶å¤¹ä¸­æ¯ä¸ª txt æ–‡ä»¶
    for ip_file in os.listdir(IP_DIR):
        if not ip_file.endswith(".txt"):
            continue

        ip_path = os.path.join(IP_DIR, ip_file)
        rtp_path = os.path.join(RTP_DIR, ip_file)
        if not os.path.exists(rtp_path):
            # æ²¡æœ‰åŒå rtp æ–‡ä»¶åˆ™è·³è¿‡
            continue

        provider_name = ip_file.replace(".txt", "")  # ç”¨äºåç¼€ï¼Œå¦‚ "å¹¿ä¸œç”µä¿¡"

        # è¯»å– ip ä¸ rtp æ–‡ä»¶å†…å®¹
        with open(ip_path, "r", encoding="utf-8") as f_ip:
            ip_lines = [line.strip() for line in f_ip if line.strip()]
        with open(rtp_path, "r", encoding="utf-8") as f_rtp:
            rtp_lines = [line.strip() for line in f_rtp if line.strip()]

        if not ip_lines or not rtp_lines:
            continue  # å†…å®¹ä¸ºç©ºåˆ™è·³è¿‡

        # åªæ£€æµ‹ rtp æ–‡ä»¶çš„ç¬¬ä¸€è¡Œï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        first_rtp_line = rtp_lines[0]
        try:
            first_channel_name, first_rtp_url = first_rtp_line.split(",", 1)
        except Exception:
            # æ ¼å¼å¼‚å¸¸ï¼Œè·³è¿‡è¯¥æ–‡ä»¶
            print(f"âš ï¸ è·³è¿‡ï¼ˆæ ¼å¼å¼‚å¸¸ï¼‰ï¼š{rtp_path}")
            continue

        # ä»…æ”¯æŒæ ‡å‡† rtp:// æ ¼å¼ï¼ˆç¬¦åˆä½ ä¹‹å‰çš„è¦æ±‚ï¼‰
        if "rtp://" not in first_rtp_url:
            print(f"âš ï¸ è·³è¿‡ï¼ˆéæ ‡å‡† rtp://ï¼‰ï¼š{first_rtp_url}")
            continue
        first_rtp_part = first_rtp_url.split("rtp://", 1)[1]

        # -------------------
        # å¤šçº¿ç¨‹æ£€æµ‹ï¼ˆåªæ£€æµ‹ç¬¬ä¸€è¡Œï¼‰ï¼š
        # è¿”å›é€šè¿‡æ£€æµ‹ï¼ˆHTTP 200ï¼‰çš„ ip_port åˆ—è¡¨ï¼ˆä¿æŒé¡ºåºå¹¶å»é‡ï¼‰
        def check_ip_for_first_rtp(ip_port):
            try:
                url = f"http://{ip_port}/rtp/{first_rtp_part}"
                resp = requests.get(url, timeout=5, stream=True)
                if resp.status_code == 200:
                    return ip_port
            except Exception:
                return None
            return None

        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            results = list(executor.map(check_ip_for_first_rtp, ip_lines))

        # ä¿ç•™æ£€æµ‹æˆåŠŸä¸”å»é‡çš„ ip é¡ºåº
        valid_ips = []
        for r in results:
            if r and r not in valid_ips:
                valid_ips.append(r)

        if not valid_ips:
            # è¯¥ provider æ²¡æœ‰å¯ç”¨ IPï¼Œè·³è¿‡
            print(f"âŒ {provider_name} æ— å¯ç”¨ IPï¼Œè·³è¿‡")
            continue

        # ä¸ºæ¯ä¸ªé€šè¿‡æ£€æµ‹çš„ IP åˆ†é…åç¼€ï¼ˆè‹¥åªæœ‰ 1 ä¸ªåˆ™ä¸ç¼–å·ï¼›è‹¥å¤šä¸ªåˆ™ç¼–å·ä»1å¼€å§‹ï¼‰
        suffix_map = {}
        if len(valid_ips) == 1:
            suffix_map[valid_ips[0]] = f"${provider_name}"
        else:
            for idx, ip_val in enumerate(valid_ips, start=1):
                suffix_map[ip_val] = f"${provider_name}{idx}"

        # ä½¿ç”¨é€šè¿‡æ£€æµ‹çš„ IP å»åˆå¹¶ rtp_linesï¼ˆåŒ…æ‹¬ç¬¬ä¸€è¡Œä¸å…¶ä»–è¡Œï¼‰
        for ip_port in valid_ips:
            suffix = suffix_map[ip_port]
            for rtp_line in rtp_lines:
                try:
                    ch_name, rtp_url_line = rtp_line.split(",", 1)
                except Exception:
                    continue
                # ä»…æ”¯æŒæ ‡å‡† rtp://ï¼Œå…¶ä½™æ ¼å¼è·³è¿‡
                if "rtp://" not in rtp_url_line:
                    continue
                rtp_part_line = rtp_url_line.split("rtp://", 1)[1]
                merged_url = f"http://{ip_port}/rtp/{rtp_part_line}"
                combined_lines.append(f"{ch_name},{merged_url}{suffix}")

    # å…¨å±€å»é‡ï¼ˆä¿ç•™åŸé¡ºåºï¼‰
    combined_lines = list(dict.fromkeys(combined_lines))

    # å†™å…¥ zubo.txtï¼ˆè¦†ç›–ï¼‰
    with open(ZUBO_FILE, "w", encoding="utf-8") as f:
        for line in combined_lines:
            f.write(line + "\n")

    print(f"ğŸ¯ ç¬¬äºŒé˜¶æ®µå®Œæˆï¼Œå·²ç”Ÿæˆ {ZUBO_FILE}ï¼Œå…± {len(combined_lines)} æ¡å”¯ä¸€ URL")

# -------------------------------
# ç¬¬73æ¬¡ï¼šæ¸…ç©º ip/ ä¸‹æ‰€æœ‰ txt å¹¶æŠŠè®¡æ•°é‡ç½®ä¸º 1ï¼ˆå¼€å§‹æ–°è½®å›ï¼‰
# æ³¨æ„ï¼šè¿™ä¸ªåˆ†æ”¯ä¸ç¬¬äºŒé˜¶æ®µå¹¶åˆ—ï¼Œå½“ run_count == 73 æ—¶ä¼šè¿è¡Œ
if run_count == 73:
    print("ğŸ§¹ run_count == 73ï¼Œå¼€å§‹æ¸…ç©º ip/ ä¸‹æ‰€æœ‰ .txt å¹¶é‡ç½®è®¡æ•°ä¸º 1")
    try:
        for file in os.listdir(IP_DIR):
            if file.endswith(".txt"):
                os.remove(os.path.join(IP_DIR, file))
                print(f"å·²åˆ é™¤ï¼š{file}")
        # å°†è®¡æ•°å†™ä¸º 1ï¼Œå¼€å§‹æ–°è½®å›
        save_run_count(1)
        print("âœ… æ¸…ç©ºå®Œæˆï¼Œè®¡æ•°å·²é‡ç½®ä¸º 1")
    except Exception as e:
        print(f"æ¸…ç©º ip/ æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")