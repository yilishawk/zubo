import os
import re
import time
import random
import requests
import concurrent.futures
import subprocess

# ===============================
# é…ç½®
FOFA_URLS = {
    "https://fofa.info/result?qbase64=InVkcHh5IiAmJiBjb3VudHJ5PSJDTiI%3D": "ip.txt",
}
HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}

COUNTER_FILE = "è®¡æ•°.txt"
IP_DIR = "ip"
RTP_DIR = "rtp"
ZUBO_FILE = "zubo.txt"
IPTV_FILE = "IPTV.txt"

CHANNEL_CATEGORIES = {
    "å¤®è§†é¢‘é“": ["CCTV1", "CCTV2"],
    "å«è§†é¢‘é“": ["æ¹–å—å«è§†", "æµ™æ±Ÿå«è§†"],
    "æ•°å­—é¢‘é“": ["CHCåŠ¨ä½œç”µå½±", "CHCå®¶åº­å½±é™¢", "CHCå½±è¿·ç”µå½±"],
}

CHANNEL_MAPPING = {
    "CCTV1": ["CCTV-1", "CCTV-1 HD", "CCTV1 HD", "CCTV-1ç»¼åˆ"],
    "CCTV2": ["CCTV-2", "CCTV-2 HD", "CCTV2 HD", "CCTV-2è´¢ç»"],
    "æ¹–å—å«è§†": ["æ¹–å—", "æ¹–å—HD", "æ¹–å—å«è§†é«˜æ¸…"],
    "æµ™æ±Ÿå«è§†": ["æµ™æ±Ÿ", "æµ™æ±ŸHD", "æµ™æ±Ÿå«è§†é«˜æ¸…"],
    "CHCåŠ¨ä½œç”µå½±": ["CHCåŠ¨ä½œ", "CHCåŠ¨ä½œHD"],
    "CHCå®¶åº­å½±é™¢": ["CHCå®¶åº­", "CHCå®¶åº­HD"],
    "CHCå½±è¿·ç”µå½±": ["CHCå½±è¿·", "CHCå½±è¿·HD"],
}

# ===============================
# è®¡æ•°é€»è¾‘
def get_run_count():
    if os.path.exists(COUNTER_FILE):
        try:
            return int(open(COUNTER_FILE).read().strip())
        except:
            return 0
    return 0

def save_run_count(count):
    open(COUNTER_FILE, "w").write(str(count))

def check_and_clear_files_by_run_count():
    os.makedirs(IP_DIR, exist_ok=True)
    count = get_run_count() + 1
    if count >= 73:
        print(f"ğŸ§¹ ç¬¬ {count} æ¬¡è¿è¡Œï¼Œæ¸…ç©º {IP_DIR} ä¸‹æ‰€æœ‰ .txt æ–‡ä»¶")
        for f in os.listdir(IP_DIR):
            if f.endswith(".txt"):
                os.remove(os.path.join(IP_DIR, f))
        save_run_count(1)
        return "w", 1
    else:
        save_run_count(count)
        return "a", count

# ===============================
# IP è¿è¥å•†åˆ¤æ–­
def get_isp(ip):
    if ip.startswith(("113.", "116.", "117.", "118.", "119.")):
        return "ç”µä¿¡"
    elif ip.startswith(("36.", "39.", "42.", "43.", "58.")):
        return "è”é€š"
    elif ip.startswith(("100.", "101.", "102.", "103.", "104.", "223.")):
        return "ç§»åŠ¨"
    return "æœªçŸ¥"

# ===============================
# ç¬¬ä¸€é˜¶æ®µï¼šæŠ“å– IP
def first_stage():
    all_ips = set()
    for url, filename in FOFA_URLS.items():
        print(f"ğŸ“¡ æ­£åœ¨çˆ¬å– {filename} ...")
        try:
            r = requests.get(url, headers=HEADERS, timeout=15)
            urls_all = re.findall(r'<a href="http://(.*?)"', r.text)
            all_ips.update(u.strip() for u in urls_all)
        except Exception as e:
            print(f"âŒ çˆ¬å–å¤±è´¥ï¼š{e}")
        time.sleep(3)

    province_isp_dict = {}
    for ip_port in all_ips:
        try:
            ip = ip_port.split(":")[0]
            res = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=10)
            data = res.json()
            province = data.get("regionName", "æœªçŸ¥")
            isp = get_isp(ip)
            if isp == "æœªçŸ¥":
                continue
            fname = f"{province}{isp}.txt"
            province_isp_dict.setdefault(fname, set()).add(ip_port)
        except Exception:
            continue

    mode, run_count = check_and_clear_files_by_run_count()
    for filename, ip_set in province_isp_dict.items():
        path = os.path.join(IP_DIR, filename)
        with open(path, mode, encoding="utf-8") as f:
            for ip_port in sorted(ip_set):
                f.write(ip_port + "\n")
        print(f"{path} å·²{'è¦†ç›–' if mode=='w' else 'è¿½åŠ '}å†™å…¥ {len(ip_set)} ä¸ª IP")
    print(f"âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼Œå½“å‰è½®æ¬¡ï¼š{run_count}")
    return run_count

# ===============================
# ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆ zubo.txt
def second_stage():
    print("ğŸ”” ç¬¬äºŒé˜¶æ®µè§¦å‘ï¼šç”Ÿæˆ zubo.txt")
    combined_lines = []
    for ip_file in os.listdir(IP_DIR):
        if not ip_file.endswith(".txt"):
            continue
        ip_path = os.path.join(IP_DIR, ip_file)
        rtp_path = os.path.join(RTP_DIR, ip_file)
        if not os.path.exists(rtp_path):
            continue

        with open(ip_path, encoding="utf-8") as f1, open(rtp_path, encoding="utf-8") as f2:
            ip_lines = [x.strip() for x in f1 if x.strip()]
            rtp_lines = [x.strip() for x in f2 if x.strip()]

        for ip_port in ip_lines:
            for rtp_line in rtp_lines:
                if "," not in rtp_line:
                    continue
                ch_name, rtp_url = rtp_line.split(",", 1)
                combined_lines.append(f"{ch_name},{'http://' + ip_port + '/rtp/' + rtp_url.split('rtp://')[1]}")

    unique = {}
    for line in combined_lines:
        url = line.split(",", 1)[1]
        if url not in unique:
            unique[url] = line

    with open(ZUBO_FILE, "w", encoding="utf-8") as f:
        for line in unique.values():
            f.write(line + "\n")

    os.system("git add zubo.txt")
    os.system('git commit -m "è‡ªåŠ¨æ›´æ–° zubo.txt" || echo "âš ï¸ æ— éœ€æäº¤"')
    os.system("git push origin main")
    print(f"ğŸ¯ ç¬¬äºŒé˜¶æ®µå®Œæˆï¼Œzubo.txt å…± {len(unique)} æ¡ URL")

# ===============================
# ç¬¬ä¸‰é˜¶æ®µï¼šæ£€æµ‹ + æµ‹é€Ÿ + åˆ†ç±»æ’åº
def normalize_channel_name(name):
    for std, aliases in CHANNEL_MAPPING.items():
        for alias in aliases:
            if alias.lower() in name.lower():
                return std
    return name.strip()

def ffprobe_check(url, timeout=5):
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-show_streams", "-i", url],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=timeout
        )
        return b"codec_type" in result.stdout
    except Exception:
        return False

def test_latency(url):
    start = time.time()
    try:
        r = requests.get(url, timeout=3, stream=True)
        next(r.iter_content(1))
        return time.time() - start
    except Exception:
        return 999
    finally:
        try:
            r.close()
        except:
            pass

def third_stage():
    print("ğŸ§© ç¬¬ä¸‰é˜¶æ®µå¼€å§‹ï¼šCCTV1 æ£€æµ‹ + æ¹–å—å«è§†æµ‹é€Ÿ + åˆ†ç±»æ’åº")
    if not os.path.exists(ZUBO_FILE):
        print("âš ï¸ æœªæ‰¾åˆ° zubo.txtï¼Œè·³è¿‡")
        return

    with open(ZUBO_FILE, encoding="utf-8") as f:
        lines = [x.strip() for x in f if x.strip() and "," in x]

    mapped = [(normalize_channel_name(x.split(",", 1)[0]), x.split(",", 1)[1]) for x in lines]

    ip_groups = {}
    for ch, url in mapped:
        m = re.search(r"http://(.*?)/", url)
        if not m:
            continue
        ip = m.group(1)
        ip_groups.setdefault(ip, []).append((ch, url))

    valid_ips = []

    # ---- Step 1: CCTV1 æ£€æµ‹ ----
    def check_ip(ip, entries):
        rep_urls = [url for ch, url in entries if ch == "CCTV1"]
        if not rep_urls:
            return None
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as exe:
            res = list(exe.map(ffprobe_check, rep_urls))
        if any(res):
            return ip, entries
        return None

    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(check_ip, ip, entries) for ip, entries in ip_groups.items()]
        for fut in concurrent.futures.as_completed(futures):
            r = fut.result()
            if r:
                valid_ips.append(r)

    # ---- Step 2: æµ‹é€Ÿ ----
    ip_speeds = []

    def speed_test(ip, entries):
        rep_urls = [url for ch, url in entries if ch == "æ¹–å—å«è§†"]
        if not rep_urls:
            rep_urls = [entries[0][1]]  # éšæœºé€‰æ‹©ä¸€ä¸ª
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as exe:
            speeds = list(exe.map(test_latency, rep_urls))
        return (ip, min(speeds))

    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
        futures = [executor.submit(speed_test, ip, entries) for ip, entries in valid_ips]
        for fut in concurrent.futures.as_completed(futures):
            ip, spd = fut.result()
            ip_speeds.append((ip, spd))

    ip_speeds.sort(key=lambda x: x[1])

    # ---- Step 3: åˆ†ç±»è¾“å‡º ----
    category_map = {cat: [] for cat in CHANNEL_CATEGORIES.keys()}
    for ip, _ in ip_speeds:
        for ch, url in ip_groups[ip]:
            for cat, names in CHANNEL_CATEGORIES.items():
                if ch in names:
                    category_map[cat].append(f"{ch},{url}")
                    break

    with open(IPTV_FILE, "w", encoding="utf-8") as f:
        for cat, lst in category_map.items():
            f.write(f"{cat},#genre#\n")
            for line in sorted(set(lst)):
                f.write(line + "\n")
            f.write("\n")

    os.system("git add IPTV.txt")
    os.system('git commit -m "è‡ªåŠ¨æ›´æ–° IPTV.txt" || echo "âš ï¸ æ— éœ€æäº¤"')
    os.system("git push origin main")
    print(f"âœ… ç¬¬ä¸‰é˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ IPTV.txt å…± {sum(len(v) for v in category_map.values())} æ¡é¢‘é“")

# ===============================
# ä¸»æµç¨‹
if __name__ == "__main__":
    run_count = first_stage()
    if run_count in [12, 24, 36, 48, 60, 72]:
        second_stage()
        third_stage()