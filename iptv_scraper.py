#!/usr/bin/env python3
"""
ğŸ¯ tonkiang.us IPTV IPæŠ“å–å·¥å…·
âœ… æŠ“å–1-4é¡µIP + çœä»½åˆ†ç±»å­˜å‚¨ + æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚
âœ… è‡ªåŠ¨åˆ›å»ºttæ–‡ä»¶å¤¹åŠçœä»½TXTæ–‡ä»¶
ä½œè€…ï¼šGrok | 2025-10-24
"""

import os
import re
import requests
from bs4 import BeautifulSoup
import logging
from pathlib import Path
from urllib.parse import urljoin

# ===============================
# ğŸ”§ æ ¸å¿ƒé…ç½®ï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
CONFIG = {
    "TARGET_DOMAIN": "https://tonkiang.us",  # ç›®æ ‡ç½‘ç«™åŸŸå
    "PAGE_RANGE": range(1, 5),  # æŠ“å–1-4é¡µï¼ˆå¦‚éœ€è°ƒæ•´ï¼Œå¦‚1-3é¡µåˆ™æ”¹ä¸ºrange(1,4)ï¼‰
    "OUTPUT_DIR": "tt",  # è¾“å‡ºæ–‡ä»¶å¤¹å
    "LOG_FILE": "tonkiang_iptv.log",  # æ—¥å¿—æ–‡ä»¶
    "TIMEOUT": 15,  # ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    # çœŸå®è¯·æ±‚å¤´ï¼ˆä»æŠ“åŒ…æ•°æ®æå–ï¼Œç¡®ä¿æŠ“å–ç¨³å®šæ€§ï¼‰
    "HEADERS": {
        ":authority": "tonkiang.us",
        ":method": "GET",
        ":scheme": "https",
        "sec-ch-ua": '"Chromium";v="140", "Not=A?Brand";v="24", "Google Chrome";v="140"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"',
        "upgrade-insecure-requests": "1",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
        "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "sec-fetch-site": "none",
        "sec-fetch-mode": "navigate",
        "sec-fetch-user": "?1",
        "sec-fetch-dest": "document",
        "accept-encoding": "gzip, deflate, br, zstd",
        "accept-language": "zh-CN,zh;q=0.9",
        # Cookieä»æŠ“åŒ…æ•°æ®æå–ï¼Œè‹¥å¤±æ•ˆéœ€é‡æ–°æ›´æ–°
        "cookie": "IPTVGO=eb6c67cc; REFERER=Gameover; REFERER2=Game; REFERER1=Over; cf_clearance=6Ya_0Q7hnBoL_Chd.LgkmHyPwIyeO_OkJlREOEqGVDw-1761270271-1.2.1.1-GG1rDyX0BUYytKFPptvP1ukG6Ep4_be48QfvGVVGaRjoVSyOgvoKI1aSTQDYFkZ97r2YTlK5aWxS5hoJgvKldYzMzW.zOxSSNYvte471UDvenZwAAuki2jrjocBA_RpQEoy.hvAeUjy_IYyQ_qGh4.D_W6khDqthvx7EB2GGDCQQ47X6TLxrgTVTi_EbgtUwQ5KkpE7hQNBYaKpTHuic3L9FgX4tFtVTyjEDVQqlCP8"
    }
}

# ===============================
# ğŸ“ æ—¥å¿—åˆå§‹åŒ–
def setup_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(CONFIG["LOG_FILE"], encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    logging.info("âœ… æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

# ===============================
# ğŸ“‚ åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆttï¼‰
def create_output_dir():
    output_dir = Path(CONFIG["OUTPUT_DIR"])
    if not output_dir.exists():
        output_dir.mkdir(parents=True)  # é€’å½’åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆè‹¥çˆ¶ç›®å½•ä¸å­˜åœ¨ä¹Ÿåˆ›å»ºï¼‰
        logging.info(f"ğŸ“ å·²åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼š{output_dir.absolute()}")
    else:
        logging.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼š{output_dir.absolute()}")
    return output_dir

# ===============================
# ğŸŒ æŠ“å–å•é¡µIPTVæ•°æ®
def scrape_single_page(page_num, output_dir):
    """æŠ“å–æŒ‡å®šé¡µç çš„IPTVæ•°æ®ï¼Œå¹¶æŒ‰çœä»½å­˜å‚¨"""
    # æ„é€ å½“å‰é¡µçš„è¯·æ±‚URL
    page_url = f"{CONFIG['TARGET_DOMAIN']}/iptvmulticast.php?page={page_num}&iphone16=&code="
    logging.info(f"ğŸ“¡ å¼€å§‹æŠ“å–ç¬¬{page_num}é¡µï¼š{page_url}")

    try:
        # å‘é€GETè¯·æ±‚ï¼ˆå¸¦çœŸå®è¯·æ±‚å¤´ï¼‰
        response = requests.get(
            url=page_url,
            headers=CONFIG["HEADERS"],
            timeout=CONFIG["TIMEOUT"],
            verify=True  # éªŒè¯SSLè¯ä¹¦ï¼ˆé¿å…å®‰å…¨é£é™©ï¼‰
        )
        response.raise_for_status()  # è‹¥çŠ¶æ€ç é200ï¼ŒæŠ›å‡ºHTTPError
        soup = BeautifulSoup(response.text, "html.parser")  # è§£æHTML

        # æå–æ‰€æœ‰åŒ…å«IPçš„.resultå®¹å™¨ï¼ˆç›®æ ‡æ•°æ®æ‰€åœ¨åŒºåŸŸï¼‰
        result_containers = soup.find_all("div", class_="result")
        if not result_containers:
            logging.warning(f"âš ï¸ ç¬¬{page_num}é¡µæœªæ‰¾åˆ°IPæ•°æ®å®¹å™¨ï¼ˆ.resultï¼‰")
            return 0

        # éå†æ¯ä¸ª.resultå®¹å™¨ï¼Œæå–IPå’Œçœä»½ä¿¡æ¯
        extracted_count = 0
        for container in result_containers:
            # 1. æå–IPåœ°å€ï¼ˆä»<a>æ ‡ç­¾çš„hrefä¸­åŒ¹é…IPï¼‰
            ip_a_tag = container.find("a", title="Channel List")  # æ‰¾åˆ°å¸¦IPçš„aæ ‡ç­¾
            if not ip_a_tag:
                logging.debug(f"âš ï¸ è·³è¿‡æ— æ•ˆå®¹å™¨ï¼šæœªæ‰¾åˆ°IPçš„aæ ‡ç­¾")
                continue

            ip_match = re.search(r"ip=([\d.]+)", ip_a_tag.get("href", ""))  # æ­£åˆ™åŒ¹é…IPï¼ˆå¦‚118.121.58.80ï¼‰
            if not ip_match:
                logging.debug(f"âš ï¸ è·³è¿‡æ— æ•ˆaæ ‡ç­¾ï¼šæœªåŒ¹é…åˆ°IP")
                continue
            ip_address = ip_match.group(1)

            # 2. æå–çœä»½ä¿¡æ¯ï¼ˆä»ç°è‰²å°å­—<i>æ ‡ç­¾ä¸­åŒ¹é…ï¼Œå¦‚â€œå››å·çœæˆéƒ½å¸‚ ç”µä¿¡â€ï¼‰
            province_i_tag = container.find("i", style=re.compile(r"font-size: 11px; color: #aaa;"))
            if not province_i_tag:
                logging.debug(f"âš ï¸ IP {ip_address} æœªæ‰¾åˆ°çœä»½ä¿¡æ¯ï¼Œæ ‡è®°ä¸ºã€ŒæœªçŸ¥çœä»½ã€")
                province = "æœªçŸ¥çœä»½"
            else:
                # æ­£åˆ™åŒ¹é…çœä»½ï¼ˆå¦‚â€œå››å·çœæˆéƒ½å¸‚â€â€œå¹¿ä¸œçœæ·±åœ³å¸‚â€ï¼Œæ’é™¤â€œç”µä¿¡â€â€œç»„æ’­â€ç­‰åç¼€ï¼‰
                province_match = re.search(r"([^çœå¸‚]+çœ[^çœå¸‚]+å¸‚|[\w]+çœ|[\w]+å¸‚) [ç»„æ’­|ç”µä¿¡|è”é€š|ç§»åŠ¨]", province_i_tag.text.strip())
                if province_match:
                    province = province_match.group(1)
                else:
                    # å…¼å®¹ç‰¹æ®Šæ ¼å¼ï¼ˆå¦‚ä»…â€œåŒ—äº¬å¸‚â€â€œä¸Šæµ·å¸‚â€ï¼‰
                    province_simple_match = re.search(r"([^ä¸Šçº¿]+)ä¸Šçº¿", province_i_tag.text.strip())
                    province = province_simple_match.group(1).strip() if province_simple_match else "æœªçŸ¥çœä»½"

            # 3. æå–é¢å¤–ä¿¡æ¯ï¼ˆå­˜æ´»å¤©æ•°ã€ä¸Šçº¿æ—¶é—´ï¼‰
            live_days_match = re.search(r"å­˜æ´»<span[^>]+><b>(\d+)</b></span>å¤©", str(container))
            live_days = live_days_match.group(1) if live_days_match else "æœªçŸ¥"

            online_time_match = re.search(r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2})ä¸Šçº¿", province_i_tag.text.strip() if province_i_tag else "")
            online_time = online_time_match.group(1) if online_time_match else "æœªçŸ¥"

            # 4. æŒ‰çœä»½å­˜å‚¨åˆ°TXTæ–‡ä»¶
            province_file = output_dir / f"{province}.txt"  # æ„é€ çœä»½æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚tt/å››å·çœæˆéƒ½å¸‚.txtï¼‰
            with open(province_file, "a", encoding="utf-8") as f:
                # å†™å…¥æ ¼å¼ï¼šIP | ä¸Šçº¿æ—¶é—´ | å­˜æ´»å¤©æ•°
                f.write(f"IP: {ip_address} | ä¸Šçº¿æ—¶é—´: {online_time} | å­˜æ´»å¤©æ•°: {live_days}å¤©\n")

            logging.debug(f"âœ… å·²æå–ï¼šIP={ip_address} | çœä»½={province} | å­˜æ´»={live_days}å¤© | ä¸Šçº¿æ—¶é—´={online_time}")
            extracted_count += 1

        logging.info(f"ğŸ‰ ç¬¬{page_num}é¡µæŠ“å–å®Œæˆï¼šå…±æå–{extracted_count}ä¸ªIPåœ°å€")
        return extracted_count

    except requests.exceptions.HTTPError as e:
        logging.error(f"âŒ ç¬¬{page_num}é¡µHTTPè¯·æ±‚é”™è¯¯ï¼š{e}ï¼ˆçŠ¶æ€ç ï¼š{response.status_code}ï¼‰")
    except requests.exceptions.ConnectionError:
        logging.error(f"âŒ ç¬¬{page_num}é¡µè¿æ¥å¤±è´¥ï¼šè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç›®æ ‡ç½‘ç«™æ˜¯å¦å¯è®¿é—®")
    except requests.exceptions.Timeout:
        logging.error(f"âŒ ç¬¬{page_num}é¡µè¯·æ±‚è¶…æ—¶ï¼šå·²è¶…è¿‡{CONFIG['TIMEOUT']}ç§’")
    except Exception as e:
        logging.error(f"âŒ ç¬¬{page_num}é¡µæŠ“å–å¼‚å¸¸ï¼š{str(e)}", exc_info=True)  # exc_info=Trueæ‰“å°è¯¦ç»†å †æ ˆ
    return 0

# ===============================
# ğŸš€ ä¸»ç¨‹åºï¼ˆæ•´åˆæ‰€æœ‰æµç¨‹ï¼‰
def run_iptv_scraper():
    logging.info("ğŸš€ tonkiang.us IPTV IPæŠ“å–å·¥å…·å¯åŠ¨")
    
    # 1. åˆå§‹åŒ–æ—¥å¿—å’Œè¾“å‡ºæ–‡ä»¶å¤¹
    setup_logging()
    output_dir = create_output_dir()

    # 2. éå†1-4é¡µæŠ“å–æ•°æ®
    total_extracted = 0
    for page in CONFIG["PAGE_RANGE"]:
        page_count = scrape_single_page(page, output_dir)
        total_extracted += page_count

    # 3. è¾“å‡ºæœ€ç»ˆç»Ÿè®¡ç»“æœ
    logging.info(f"ğŸŠ æ‰€æœ‰é¡µé¢æŠ“å–å®Œæˆï¼")
    logging.info(f"ğŸ“Š ç»Ÿè®¡ï¼šå…±æŠ“å–{len(CONFIG['PAGE_RANGE'])}é¡µï¼Œç´¯è®¡æå–{total_extracted}ä¸ªIPåœ°å€")
    logging.info(f"ğŸ“ ç»“æœå­˜å‚¨è·¯å¾„ï¼š{output_dir.absolute()}ï¼ˆæŒ‰çœä»½åˆ†ç±»çš„TXTæ–‡ä»¶ï¼‰")

# ===============================
if __name__ == "__main__":
    run_iptv_scraper()
