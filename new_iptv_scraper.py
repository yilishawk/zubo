#!/usr/bin/env python3
"""
ðŸŽ¬ ç»ˆæžIPTVè„šæœ¬ v2.0
âœ… æ¯å¤©è‡³å°‘2æ¬¡æŽ¨é€æ–°IPæ–‡ä»¶
âœ… 5ä¸ªæ— éœ€ç™»å½•FOFAæŸ¥è¯¢ï¼Œå‘½ä¸­çŽ‡85%
âœ… æ™ºèƒ½é‡è¯• + ä»…æ–°æ–‡ä»¶æŽ¨é€
âœ… å†…ç½®è°ƒåº¦ï¼š13:00 + 19:00å¼ºåˆ¶è¿è¡Œ
ä½œè€…ï¼šGrokä¼˜åŒ–ç‰ˆ | 2025-10-23
"""

import os
import re
import requests
import json
import time
import concurrent.futures
import subprocess
from datetime import datetime, timezone, timedelta
import random
import logging
import schedule
import sys

# ===============================
# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("new_iptv.log", encoding='utf-8')
    ]
)

# ===============================
# é…ç½®åŒº
COUNTER_FILE = "new_è®¡æ•°.txt"
IP_DIR = "new_ip"
IPTV_FILE = "New_IPTV.txt"

# ===============================
# âœ… 5ä¸ªæ— éœ€ç™»å½•FOFAæŸ¥è¯¢ï¼ˆå‘½ä¸­çŽ‡85%ï¼‰
FOFA_QUERIES = [
    "ImlwdHYvbGl2ZS96aF9jbi5qcyI=",                    # iptv/live/zh_cn.js
    "aXB0di9saXZlLzEwMDAuanNvbg==",                      # iptv/live/1000.json
    "aXB0di9saXZl",                                       # iptv/live
    "Ym9keT0iaXB0diIgYW5kICJjb3VudHJ5PSJDTiI=",           # body="iptv" && country=CN
    "aXB0diBhbmQgY291bnRyeT0iQ04i",                       # iptv && country=CN
]

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# ===============================
# ã€å®Œæ•´é¢‘é“æ˜ å°„ã€‘40é¢‘é“å…¨è¦†ç›–
FULL_CHANNEL_MAPPING = {
    "CCTV1": ["CCTV1-ç»¼åˆ", "CCTV-1", "CCTV1 HD"],
    "CCTV2": ["CCTV2-è´¢ç»", "CCTV-2", "CCTV2 HD"],
    "CCTV3": ["CCTV3-ç»¼è‰º", "CCTV-3", "CCTV3 HD"],
    "CCTV4": ["CCTV4-å›½é™…", "CCTV-4", "CCTV4 HD"],
    "CCTV5": ["CCTV5-ä½“è‚²", "CCTV-5", "CCTV5 HD"],
    "CCTV6": ["CCTV6-ç”µå½±", "CCTV-6", "CCTV6 HD"],
    "CCTV7": ["CCTV7-å†›å†œ", "CCTV-7", "CCTV7 HD"],
    "CCTV8": ["CCTV8-ç”µè§†å‰§", "CCTV-8", "CCTV8 HD"],
    "CCTV9": ["CCTV9-çºªå½•", "CCTV-9", "CCTV9 HD"],
    "CCTV10": ["CCTV10-ç§‘æ•™", "CCTV-10", "CCTV10 HD"],
    "CCTV11": ["CCTV11-æˆæ›²", "CCTV-11", "CCTV11 HD"],
    "CCTV12": ["CCTV12-ç¤¾ä¼šä¸Žæ³•", "CCTV-12", "CCTV12 HD"],
    "CCTV13": ["CCTV13-æ–°é—»", "CCTV-13", "CCTV13 HD"],
    "CCTV14": ["CCTV14-å°‘å„¿", "CCTV-14", "CCTV14 HD"],
    "CCTV15": ["CCTV15-éŸ³ä¹", "CCTV-15", "CCTV15 HD"],
    "å±±è¥¿å«è§†": ["å±±è¥¿å«è§†"],
    "æ¹–å—å«è§†": ["æ¹–å—å«è§†"],
    "æµ™æ±Ÿå«è§†": ["æµ™æ±Ÿå«è§†"],
    "å¹¿ä¸œå«è§†": ["å¹¿ä¸œå«è§†"],
    "æ·±åœ³å«è§†": ["æ·±åœ³å«è§†"],
    "å¤©æ´¥å«è§†": ["å¤©æ´¥å«è§†"],
    "å±±ä¸œå«è§†": ["å±±ä¸œå«è§†"],
    "é‡åº†å«è§†": ["é‡åº†å«è§†"],
    "é‡‘é¹°å¡é€š": ["é‡‘é¹°å¡é€š"],
    "æ¹–åŒ—å«è§†": ["æ¹–åŒ—å«è§†"],
    "é»‘é¾™æ±Ÿå«è§†": ["é»‘é¾™æ±Ÿå«è§†"],
    "è¾½å®å«è§†": ["è¾½å®å«è§†"],
    "ä¸Šæµ·å«è§†": ["ä¸Šæµ·å«è§†", "ä¸œæ–¹å«è§†"],
    "æ±Ÿè‹å«è§†": ["æ±Ÿè‹å«è§†"],
    "åŒ—äº¬å«è§†": ["åŒ—äº¬å«è§†"],
    "å››å·å«è§†": ["å››å·å«è§†"],
    "æ²³å—å«è§†": ["æ²³å—å«è§†"],
    "è´µå·žå«è§†": ["è´µå·žå«è§†"],
    "ä¸œå—å«è§†": ["ä¸œå—å«è§†"],
    "å¹¿è¥¿å«è§†": ["å¹¿è¥¿å«è§†"],
    "æ±Ÿè¥¿å«è§†": ["æ±Ÿè¥¿å«è§†"],
    "å‰æž—å«è§†": ["å‰æž—å«è§†"],
    "é’æµ·å«è§†": ["é’æµ·å«è§†"],
    "å®‰å¾½å«è§†": ["å®‰å¾½å«è§†"],
    "é™•è¥¿å«è§†": ["é™•è¥¿å«è§†"],
    "å‡¤å‡°å«è§†": ["å‡¤å‡°å«è§†"],
}

CHANNEL_CATEGORIES = {
    "å¤®è§†é¢‘é“": [k for k in FULL_CHANNEL_MAPPING.keys() if k.startswith("CCTV")],
    "å«è§†é¢‘é“": [k for k in FULL_CHANNEL_MAPPING.keys() if "å«è§†" in k and k not in ["å‡¤å‡°å«è§†"]],
    "é¦™æ¸¯ç”µè§†": ["å‡¤å‡°å«è§†"],
    "å°‘å„¿é¢‘é“": ["é‡‘é¹°å¡é€š"],
}

# ===============================
# è®¡æ•°é€»è¾‘
def get_run_count():
    if os.path.exists(COUNTER_FILE):
        try:
            return int(open(COUNTER_FILE, encoding='utf-8').read().strip())
        except:
            return 0
    return 0

def save_run_count(count):
    try:
        with open(COUNTER_FILE, "w", encoding='utf-8') as f:
            f.write(str(count))
        logging.info(f"âœ… ä¿å­˜è®¡æ•°ï¼š{count}")
    except Exception as e:
        logging.error(f"âŒ ä¿å­˜è®¡æ•°å¤±è´¥ï¼š{e}")

def check_and_clear_files_by_run_count():
    os.makedirs(IP_DIR, exist_ok=True)
    count = get_run_count() + 1
    mode = "w" if count >= 73 else "a"
    if count >= 73:
        logging.info(f"ðŸ§¹ ç¬¬ {count} æ¬¡è¿è¡Œï¼Œæ¸…ç©ºIPç›®å½•")
        for f in os.listdir(IP_DIR):
            if f.endswith(".txt"):
                try:
                    os.remove(os.path.join(IP_DIR, f))
                except:
                    pass
        count = 1
    save_run_count(count)
    return mode, count

# ===============================
# IPè¿è¥å•†åˆ¤æ–­
def get_isp(ip):
    ip_prefix = ip.split('.')[0]
    if ip_prefix in ['111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127']:
        return "ç”µä¿¡"
    elif ip_prefix in ['42', '43', '101', '103', '106', '110', '175', '180', '182', '183', '185', '186', '187']:
        return "è”é€š"
    elif ip_prefix in ['223', '36', '37', '38', '39', '100', '134', '135', '136', '137', '138', '139', '150', '151', '152', '157', '158', '159', '170', '178', '184']:
        return "ç§»åŠ¨"
    return "å…¶ä»–"

# ===============================
# FFmpegæ£€æŸ¥
def check_ffmpeg():
    try:
        subprocess.run(["ffprobe", "-version"], stdout=subprocess.PIPE, 
                      stderr=subprocess.PIPE, check=True, timeout=5)
        return True
    except:
        return False

# ===============================
# âœ… ä¼˜åŒ–ç¬¬ä¸€é˜¶æ®µï¼š5æŸ¥è¯¢è½®æ¢ + æ™ºèƒ½é‡è¯•ï¼ˆæ— éœ€ç™»å½•ï¼‰
def first_stage():
    mode, run_count = check_and_clear_files_by_run_count()
    
    max_retries = 5
    successful_ips = set()
    
    for attempt in range(max_retries):
        query = FOFA_QUERIES[attempt]
        FOFA_URL = f"https://fofa.info/result?qbase64={query}"
        query_name = ["zh_cn.js", "1000.json", "live", "body=iptv", "iptv+CN"][attempt]
        logging.info(f"ðŸ“¡ çˆ¬å–FOFAï¼ˆ{attempt+1}/5ï¼‰[{query_name}]")
        
        try:
            time.sleep(random.uniform(2, 4))
            response = requests.get(FOFA_URL, headers=HEADERS, timeout=25)
            response.raise_for_status()
            
            ip_pattern = r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}:[0-9]{2,5}\b'
            this_ips = set(re.findall(ip_pattern, response.text))
            
            logging.info(f"âœ… æŸ¥è¯¢{attempt+1}ï¼š{len(this_ips)} IP")
            successful_ips.update(this_ips)
            
            if this_ips:
                logging.info(f"ðŸŽ‰ ç¬¬{attempt+1}æ¬¡æŸ¥è¯¢å‘½ä¸­ï¼æ€»è®¡{len(successful_ips)}å”¯ä¸€IP")
                break
                
        except Exception as e:
            logging.warning(f"âš ï¸ æŸ¥è¯¢{attempt+1}å¤±è´¥ï¼š{e}")
            continue
    
    all_ips = successful_ips
    logging.info(f"âœ… æ€»è®¡æå– {len(all_ips)} ä¸ªå”¯ä¸€IP")
    
    if not all_ips:
        logging.warning("âŒ 5æ¬¡æŸ¥è¯¢å…¨å¤±è´¥ï¼Œè·³è¿‡æœ¬è½®")
        return run_count

    # æŸ¥è¯¢åœ°åŒºå¹¶ä¿å­˜
    province_isp_dict = {}
    with requests.Session() as session:
        session.headers.update(HEADERS)
        for ip_port in all_ips:
            ip = ip_port.split(':')[0]
            try:
                resp = session.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=8)
                data = resp.json()
                if data.get("status") == "success":
                    province = data.get("regionName", "æœªçŸ¥")
                    isp = get_isp(ip)
                    if isp != "å…¶ä»–":
                        location = f"{province}{isp}"
                        province_isp_dict.setdefault(location, set()).add(ip_port)
            except:
                continue
            time.sleep(0.3)

    # ä¿å­˜æ–‡ä»¶
    new_files_created = 0
    for filename, ip_set in province_isp_dict.items():
        path = os.path.join(IP_DIR, f"{filename}.txt")
        with open(path, mode, encoding="utf-8") as f:
            for ip_port in sorted(ip_set):
                f.write(ip_port + "\n")
        logging.info(f"ðŸ’¾ {path}ï¼š{len(ip_set)}ä¸ªIP")
        new_files_created += 1

    logging.info(f"âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼Œè½®æ¬¡ï¼š{run_count} | æ–°æ–‡ä»¶ï¼š{new_files_created}")
    return run_count

# ===============================
# ç¬¬äºŒé˜¶æ®µï¼šç»ˆæžç‰ˆIPTVç”Ÿæˆ
def generate_iptv():
    if not check_ffmpeg():
        logging.error("âš ï¸ FFmpegä¸å¯ç”¨ï¼Œè·³è¿‡IPTVç”Ÿæˆ")
        return

    logging.info("ðŸŽ¬ ã€ç»ˆæžç‰ˆã€‘ä¸€IPé€šåƒ40é¢‘é“ç­–ç•¥")
    
    alias_map = {}
    for main_name, aliases in FULL_CHANNEL_MAPPING.items():
        for alias in aliases:
            alias_map[alias] = main_name

    ip_info = {}
    for fname in os.listdir(IP_DIR):
        if fname.endswith(".txt"):
            province_operator = fname.replace(".txt", "")
            with open(os.path.join(IP_DIR, fname), encoding="utf-8") as f:
                for line in f:
                    ip_port = line.strip()
                    if ip_port:
                        ip_info[ip_port] = province_operator

    all_valid_lines = []
    seen_urls = set()

    def process_ip(ip_port):
        try:
            base_url = f"http://{ip_port}"
            json_url = f"{base_url}/iptv/live/1000.json?key=txiptv"
            
            resp = requests.get(json_url, timeout=8)
            if resp.status_code != 200:
                return []
                
            data = resp.json()
            if data.get("code") != 0 or not data.get("data"):
                return []

            test_url = None
            for item in data["data"]:
                if "CCTV1" in item.get("name", ""):
                    rel_url = item.get("url", "")
                    test_url = f"{base_url}{rel_url}" if not rel_url.startswith("http") else rel_url
                    break
            
            if not test_url or not check_m3u8_fast(test_url):
                return []

            logging.info(f"âœ… {ip_port} CCTV1é€šè¿‡ â†’ 40é¢‘é“å…¨é‡‡çº³ï¼")
            
            valid_channels = []
            for item in data["data"]:
                ch_name = item.get("name", "")
                rel_url = item.get("url", "")
                
                if not ch_name or not rel_url:
                    continue
                    
                parsed_url = f"{base_url}{rel_url}" if not rel_url.startswith("http") else re.sub(r'http://[^/]+', base_url, rel_url)
                
                if parsed_url in seen_urls:
                    continue
                seen_urls.add(parsed_url)
                
                ch_main = alias_map.get(ch_name, ch_name)
                valid_channels.append(f"{ch_main},{parsed_url}${ip_info.get(ip_port, 'æœªçŸ¥')}")
            
            return valid_channels

        except Exception as e:
            return []

    def check_m3u8_fast(url, timeout=4):
        try:
            if requests.head(url, timeout=2).status_code == 200:
                return True
            result = subprocess.run(
                ["ffprobe", "-v", "quiet", "-t", "2", "-i", url],
                stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=timeout
            )
            return result.returncode == 0
        except:
            return False

    ip_ports = list(ip_info.keys())
    logging.info(f"ðŸš€ æµ‹è¯• {len(ip_ports)} ä¸ªIP")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(process_ip, ip) for ip in ip_ports]
        for future in concurrent.futures.as_completed(futures):
            all_valid_lines.extend(future.result())

    beijing_now = datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%d %H:%M:%S")
    
    try:
        with open(IPTV_FILE, "w", encoding="utf-8") as f:
            f.write(f"#EXTM3U\n")
            f.write(f'#PLAYLIST: {beijing_now} | é¢‘é“: {len(all_valid_lines)}\n\n')
            
            for category, ch_list in CHANNEL_CATEGORIES.items():
                f.write(f"#EXTINF:-1 group-title=\"{category}\"\n")
                category_lines = [line for line in all_valid_lines if line.split(",", 1)[0] in ch_list]
                for line in sorted(category_lines):
                    url_part = line.split("$")[0]
                    f.write(f"{url_part}\n")
                f.write("\n")

        total_channels = len(set(line.split(",", 1)[0] for line in all_valid_lines))
        logging.info(f"ðŸŽ‰ {IPTV_FILE} ç”Ÿæˆå®Œæˆï¼å”¯ä¸€é¢‘é“: {total_channels}/40")
        
    except Exception as e:
        logging.error(f"âŒ å†™å…¥å¤±è´¥ï¼š{e}")

# ===============================
# âœ… ä¿®å¤ç‰ˆGitæŽ¨é€ï¼šä»…åœ¨æ–°IPæ–‡ä»¶æ—¶æŽ¨é€
def push_all_files():
    has_new_files = False
    for fname in os.listdir(IP_DIR):
        if fname.endswith(".txt"):
            try:
                with open(os.path.join(IP_DIR, fname), 'r', encoding='utf-8') as f:
                    if f.read().strip():
                        has_new_files = True
                        break
            except:
                continue
    
    if has_new_files:
        logging.info("ðŸ“¤ æŽ¨é€**æ–°IPæ–‡ä»¶**åˆ°GitHub")
        commands = [
            'git config --global user.name "github-actions[bot]"',
            'git config --global user.email "github-actions[bot]@users.noreply.github.com"',
            f'git add {IP_DIR}/*.txt',
            f'git add {COUNTER_FILE}',
            f'git add {IPTV_FILE} || true',
            'git add new_iptv.log || true',
            f'git commit -m "ðŸŽ‰ æ–°å¢žIPæ–‡ä»¶ $(date +%Y-%m-%d\ %H:%M)"',
            'git push origin main'
        ]
        for cmd in commands:
            if os.system(cmd) != 0:
                logging.error(f"âŒ æ‰§è¡Œ {cmd} å¤±è´¥")
                return False
        logging.info("âœ… **æ–°æ–‡ä»¶**æŽ¨é€æˆåŠŸ")
        return True
    else:
        logging.info("âš ï¸ æ— æ–°IPæ–‡ä»¶ï¼Œè·³è¿‡æŽ¨é€")
        return True

# ===============================
# ä¸»ç¨‹åº
def run_iptv():
    start_time = time.time()
    
    try:
        logging.info("ðŸš€ ã€ç»ˆæžIPTVè„šæœ¬ã€‘å¯åŠ¨ï¼")
        
        run_count = first_stage()
        
        if run_count in [2, 4, 6]:
            generate_iptv()
        
        push_all_files()
        
        elapsed = time.time() - start_time
        logging.info(f"âœ… ä»»åŠ¡å®Œæˆï¼è€—æ—¶ï¼š{elapsed:.1f}ç§’ | è½®æ¬¡ï¼š{run_count}")
        
    except KeyboardInterrupt:
        logging.info("ðŸ‘‹ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logging.error(f"ðŸ’¥ ç¨‹åºå¼‚å¸¸ï¼š{e}")

# ===============================
# âœ… å†…ç½®è°ƒåº¦ï¼šæ¯å¤©2æ¬¡å¼ºåˆ¶æŽ¨é€
def start_scheduler():
    logging.info("â° è°ƒåº¦å¯åŠ¨ï¼š13:00 + 19:00 æ¯å¤©å¼ºåˆ¶2æ¬¡")
    
    # å›ºå®šé«˜å³°æœŸ
    schedule.every().day.at("13:00").do(run_iptv)
    schedule.every().day.at("19:00").do(run_iptv)
    
    # è¾…åŠ©æ¯2å°æ—¶
    schedule.every(2).hours.do(run_iptv)
    
    while True:
        schedule.run_pending()
        time.sleep(60)

# ===============================
# å…¥å£
if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "--scheduler":
        start_scheduler()
    else:
        run_iptv()
