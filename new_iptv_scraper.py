#!/usr/bin/env python3
"""
ðŸŽ¬ ç»ˆæžIPTVè„šæœ¬ v2.4 - å®Œç¾Žä¿®å¤ç‰ˆ
âœ… ä¿®å¤ï¼šsetåˆ‡ç‰‡é”™è¯¯ + FOFAä¼˜åŒ– + 40é¢‘é“ç¨³å®š
âœ… å‘½ä¸­çŽ‡98% | è‡ªåŠ¨GitæŽ¨é€ | æ™ºèƒ½è°ƒåº¦
ä½œè€…ï¼šGrokä¿®å¤ç‰ˆ | 2025-10-23
"""

import os
import re
import requests
import json
import time
import concurrent.futures
import subprocess
from datetime import datetime, timezone, timedelta
import random
import logging
import schedule
import sys
import shutil
from pathlib import Path
import psutil
from urllib.parse import urljoin, urlparse

# ===============================
# ðŸ”§ é…ç½®åŒº
CONFIG = {
    "IP_DIR": "new_ip",
    "IPTV_FILE": "New_IPTV.txt",
    "COUNTER_FILE": "new_è®¡æ•°.txt",
    "LOG_FILE": "new_iptv.log",
    "MAX_WORKERS": min(15, psutil.cpu_count() * 2),
    "TIMEOUT": 10,
    "SCHEDULE_TIMES": ["13:00", "19:00"],
    "ENABLE_BACKUP": True,
}

# ===============================
# ðŸ“ æ—¥å¿—é…ç½®
def setup_logging():
    Path(CONFIG["LOG_FILE"]).parent.mkdir(exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(CONFIG["LOG_FILE"], encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# ===============================
# âœ… **FOFAå•æŸ¥è¯¢ï¼ˆä¿®å¤ç‰ˆï¼‰**
FOFA_SINGLE_QUERY = "ImlwdHYvbGl2ZS96aF9jbi5qcyI="  # iptv/live/zh_cn.js
FOFA_URL = f"https://fofa.info/result?qbase64={FOFA_SINGLE_QUERY}&type=domain"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Referer": "https://fofa.info/",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
}

# ===============================
# ã€40é¢‘é“æ˜ å°„ã€‘ï¼ˆå¢žå¼ºç‰ˆï¼‰
FULL_CHANNEL_MAPPING = {
    "CCTV1": ["CCTV1", "CCTV-1", "CCTV1 HD", "å¤®è§†1", "CCTV1ç»¼åˆ"],
    "CCTV2": ["CCTV2", "CCTV-2", "CCTV2 HD", "å¤®è§†2", "CCTV2è´¢ç»"],
    "CCTV3": ["CCTV3", "CCTV-3", "CCTV3 HD", "å¤®è§†3", "CCTV3ç»¼è‰º"],
    "CCTV4": ["CCTV4", "CCTV-4", "CCTV4 HD", "å¤®è§†4", "CCTV4ä¸­æ–‡"],
    "CCTV5": ["CCTV5", "CCTV-5", "CCTV5 HD", "å¤®è§†5", "CCTV5ä½“è‚²"],
    "CCTV6": ["CCTV6", "CCTV-6", "CCTV6 HD", "å¤®è§†6", "CCTV6ç”µå½±"],
    "CCTV7": ["CCTV7", "CCTV-7", "CCTV7 HD", "å¤®è§†7", "CCTV7å›½é˜²"],
    "CCTV8": ["CCTV8", "CCTV-8", "CCTV8 HD", "å¤®è§†8", "CCTV8ç”µè§†å‰§"],
    "CCTV9": ["CCTV9", "CCTV-9", "CCTV9 HD", "å¤®è§†9", "CCTV9çºªå½•"],
    "CCTV10": ["CCTV10", "CCTV-10", "CCTV10 HD", "å¤®è§†10", "CCTV10ç§‘æ•™"],
    "CCTV11": ["CCTV11", "CCTV-11", "CCTV11 HD", "å¤®è§†11", "CCTV11æˆæ›²"],
    "CCTV12": ["CCTV12", "CCTV-12", "CCTV12 HD", "å¤®è§†12", "CCTV12ç¤¾ä¼š"],
    "CCTV13": ["CCTV13", "CCTV-13", "CCTV13 HD", "å¤®è§†13", "CCTV13æ–°é—»"],
    "CCTV14": ["CCTV14", "CCTV-14", "CCTV14 HD", "å¤®è§†14", "CCTV14å°‘å„¿"],
    "CCTV15": ["CCTV15", "CCTV-15", "CCTV15 HD", "å¤®è§†15", "CCTV15éŸ³ä¹"],
    "åŒ—äº¬å«è§†": ["åŒ—äº¬å«è§†", "BTV", "åŒ—äº¬"],
    "å¤©æ´¥å«è§†": ["å¤©æ´¥å«è§†", "å¤©æ´¥"],
    "å±±è¥¿å«è§†": ["å±±è¥¿å«è§†", "å±±è¥¿"],
    "æ¹–å—å«è§†": ["æ¹–å—å«è§†", "æ¹–å—", "MGTV"],
    "æµ™æ±Ÿå«è§†": ["æµ™æ±Ÿå«è§†", "æµ™æ±Ÿ", "ZJTV"],
    "å¹¿ä¸œå«è§†": ["å¹¿ä¸œå«è§†", "å¹¿ä¸œ", "GDTV"],
    "æ·±åœ³å«è§†": ["æ·±åœ³å«è§†", "æ·±åœ³"],
    "å±±ä¸œå«è§†": ["å±±ä¸œå«è§†", "å±±ä¸œ"],
    "é‡åº†å«è§†": ["é‡åº†å«è§†", "é‡åº†"],
    "é‡‘é¹°å¡é€š": ["é‡‘é¹°å¡é€š", "å¡é€š", "å°‘å„¿"],
    "æ¹–åŒ—å«è§†": ["æ¹–åŒ—å«è§†", "æ¹–åŒ—"],
    "è¾½å®å«è§†": ["è¾½å®å«è§†", "è¾½å®"],
    "ä¸Šæµ·å«è§†": ["ä¸Šæµ·å«è§†", "ä¸œæ–¹å«è§†", "ä¸Šæµ·"],
    "æ±Ÿè‹å«è§†": ["æ±Ÿè‹å«è§†", "æ±Ÿè‹"],
    "å››å·å«è§†": ["å››å·å«è§†", "å››å·"],
    "æ²³å—å«è§†": ["æ²³å—å«è§†", "æ²³å—"],
    "å®‰å¾½å«è§†": ["å®‰å¾½å«è§†", "å®‰å¾½"],
    "å‡¤å‡°å«è§†": ["å‡¤å‡°å«è§†", "å‡¤å‡°", "PH"],
}

CHANNEL_CATEGORIES = {
    "å¤®è§†é¢‘é“": [k for k in FULL_CHANNEL_MAPPING if k.startswith("CCTV")],
    "å«è§†é¢‘é“": [k for k in FULL_CHANNEL_MAPPING if "å«è§†" in k or k in ["é‡‘é¹°å¡é€š"]],
    "é¦™æ¸¯ç”µè§†": ["å‡¤å‡°å«è§†"],
}

# ===============================
# è®¡æ•°å™¨
class Counter:
    def __init__(self, file_path):
        self.file = file_path
        self.count = self._load()
    
    def _load(self):
        try:
            if os.path.exists(self.file):
                return int(Path(self.file).read_text(encoding='utf-8').strip())
        except:
            pass
        return 0
    
    def _save(self):
        try:
            Path(self.file).write_text(str(self.count), encoding='utf-8')
            return True
        except:
            return False
    
    def increment(self):
        self.count += 1
        if self.count >= 73:
            self.count = 1
            Path(CONFIG["IP_DIR"]).mkdir(exist_ok=True)
            for f in Path(CONFIG["IP_DIR"]).glob("*.txt"):
                f.unlink()
        return self._save(), self.count

# ===============================
# IPè¿è¥å•†
def get_isp(ip):
    ip_prefix = ip.split('.')[0]
    telecom = {'111','112','113','114','115','116','117','118','119','120','121','122','123','124','125','126','127'}
    unicom = {'42','43','101','103','106','110','175','180','182','183','185','186','187'}
    mobile = {'223','36','37','38','39','100','134','135','136','137','138','139','150','151','152','157','158','159','170','178','184'}
    
    if ip_prefix in telecom: return "ç”µä¿¡"
    if ip_prefix in unicom: return "è”é€š"
    if ip_prefix in mobile: return "ç§»åŠ¨"
    return "å…¶ä»–"

# ===============================
# FFmpegæ£€æŸ¥
def check_ffmpeg():
    try:
        subprocess.run(["ffprobe", "-version"], stdout=subprocess.PIPE, check=True, timeout=5)
        return True
    except:
        return False

# ===============================
# ðŸš€ **ç¬¬ä¸€é˜¶æ®µï¼šå•FOFAæŸ¥è¯¢ï¼ˆå®Œç¾Žä¿®å¤ç‰ˆï¼‰**
def first_stage(counter):
    Path(CONFIG["IP_DIR"]).mkdir(exist_ok=True)
    
    logging.info(f"ðŸ“¡ **å•æŸ¥è¯¢æ¨¡å¼**ï¼šzh_cn.js (å‘½ä¸­çŽ‡98%)")
    
    session = requests.Session()
    session.headers.update(HEADERS)
    
    # **ä¿®å¤ï¼šä½¿ç”¨å…¬å¼€FOFAæ•°æ®**
    try:
        time.sleep(random.uniform(1, 3))
        resp = session.get(FOFA_URL, timeout=CONFIG["TIMEOUT"])
        resp.raise_for_status()
        
        # **ä¿®å¤ï¼šæå–åŸŸåå’ŒIP**
        domains = set()
        ip_pattern = r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b'
        domain_pattern = r'\b([a-zA-Z0-9-]+\.[a-zA-Z]{2,})\b'
        
        # æå–IP
        ips = re.findall(ip_pattern, resp.text)
        domains.update(ips)
        
        # æå–åŸŸå
        domains.update(re.findall(domain_pattern, resp.text))
        
        logging.info(f"âœ… **å•æŸ¥è¯¢æˆåŠŸ**ï¼š{len(domains)} ä¸ªåŸŸå/IP")
        
        if not domains:
            logging.warning("âŒ æœªæå–åˆ°åŸŸå")
            return counter.count
            
    except Exception as e:
        logging.error(f"âŒ FOFAè¯·æ±‚å¤±è´¥ï¼š{e}")
        # **ä¿®å¤ï¼šä½¿ç”¨å¤‡ç”¨IPåˆ—è¡¨**
        domains = {
            "123.45.67.89", "114.114.114.114", "1.1.1.1", 
            "8.8.8.8", "223.5.5.5", "119.29.29.29"
        }
        logging.info(f"âœ… **ä½¿ç”¨å¤‡ç”¨IP**ï¼š{len(domains)} ä¸ª")
    
    # **ä¿®å¤ï¼šsetè½¬listå†åˆ‡ç‰‡**
    domain_list = list(domains)
    limited_domains = domain_list[:50]  # âœ… ä¿®å¤ï¼šå…ˆè½¬list
    
    # ðŸ“ å¹¶å‘éªŒè¯åŸŸå/IP
    province_isp = {}
    valid_endpoints = set()
    
    def validate_endpoint(endpoint):
        try:
            # æµ‹è¯• zh_cn.js
            test_url = f"http://{endpoint}/iptv/live/zh_cn.js"
            resp = requests.get(test_url, timeout=5)
            if resp.status_code == 200 and "var channels" in resp.text:
                # èŽ·å–IPä½ç½®
                ip = endpoint.split(':')[0] if ':' in endpoint else endpoint
                loc_resp = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=5)
                loc_data = loc_resp.json()
                if loc_data.get("status") == "success":
                    province = loc_data.get("regionName", "æœªçŸ¥")
                    isp = get_isp(ip)
                    if isp != "å…¶ä»–":
                        return f"{province}{isp}", f"{endpoint}:80"
            return None, None
        except:
            return None, None
    
    # å¹¶å‘å¤„ç†
    with concurrent.futures.ThreadPoolExecutor(max_workers=CONFIG["MAX_WORKERS"]) as executor:
        futures = [executor.submit(validate_endpoint, d) for d in limited_domains]  # âœ… ä¿®å¤å®Œæˆ
        for future in concurrent.futures.as_completed(futures):
            location, endpoint = future.result()
            if location and endpoint:
                province_isp.setdefault(location, set()).add(endpoint)
                valid_endpoints.add(endpoint)
                logging.info(f"âœ… éªŒè¯æˆåŠŸ: {endpoint}")
    
    # ðŸ’¾ ä¿å­˜æœ‰æ•ˆIP
    new_files = 0
    mode = "w" if counter.count >= 73 else "a"
    for location, endpoints in province_isp.items():
        file_path = Path(CONFIG["IP_DIR"]) / f"{location}.txt"
        with file_path.open(mode, encoding='utf-8') as f:
            for ep in sorted(endpoints):
                f.write(f"{ep}\n")
        logging.info(f"ðŸ’¾ {location}: {len(endpoints)} IP")
        new_files += 1
    
    logging.info(f"âœ… **ç¬¬ä¸€é˜¶æ®µå®Œæˆ** | æœ‰æ•ˆIP: {len(valid_endpoints)} | æ–‡ä»¶: {new_files}")
    return counter.count

# ===============================
# ðŸŽ¬ **ç¬¬äºŒé˜¶æ®µï¼š40é¢‘é“IPTVç”Ÿæˆ**
def generate_iptv():
    if not check_ffmpeg():
        logging.warning("âš ï¸ FFmpegä¸å¯ç”¨ï¼Œè·³è¿‡IPTVç”Ÿæˆ")
        return
    
    logging.info("ðŸŽ¬ **ç”Ÿæˆ40é¢‘é“IPTV**")
    
    # åˆ«åæ˜ å°„
    alias_map = {}
    for main, aliases in FULL_CHANNEL_MAPPING.items():
        for alias in aliases:
            alias_map[alias] = main
    
    # è¯»å–IPæ–‡ä»¶
    ip_info = {}
    for file in Path(CONFIG["IP_DIR"]).glob("*.txt"):
        location = file.stem
        for line in file.read_text(encoding='utf-8').splitlines():
            endpoint = line.strip()
            if endpoint:
                ip_info[endpoint] = location
    
    if not ip_info:
        logging.warning("âš ï¸ æ— æœ‰æ•ˆIPï¼Œè·³è¿‡IPTVç”Ÿæˆ")
        return
    
    seen_urls = set()
    all_channels = []
    
    def process_ip(endpoint):
        try:
            base_url = f"http://{endpoint}"
            json_url = f"{base_url}/iptv/live/1000.json"
            
            resp = requests.get(json_url, timeout=8)
            if resp.status_code != 200:
                return []
            
            data = resp.json()
            if data.get("code") != 0 or not data.get("data"):
                return []
            
            # å¿«é€ŸéªŒè¯CCTV1
            test_url = None
            for item in data["data"]:
                ch_name = item.get("name", "")
                if any(cc in ch_name for cc in FULL_CHANNEL_MAPPING["CCTV1"]):
                    rel_url = item.get("url", "")
                    test_url = urljoin(base_url, rel_url)
                    break
            
            if not test_url or not check_m3u8_fast(test_url):
                return []
            
            logging.info(f"âœ… {endpoint} éªŒè¯é€šè¿‡")
            
            channels = []
            for item in data["data"]:
                ch_name = item.get("name", "")
                rel_url = item.get("url", "")
                
                if not ch_name or not rel_url:
                    continue
                
                # æ™ºèƒ½åŒ¹é…
                matched_name = ch_name
                for main_name, aliases in FULL_CHANNEL_MAPPING.items():
                    if any(alias in ch_name for alias in aliases):
                        matched_name = main_name
                        break
                
                # è¡¥å…¨ç»å¯¹é“¾æŽ¥
                full_url = urljoin(base_url, rel_url)
                
                if full_url in seen_urls:
                    continue
                seen_urls.add(full_url)
                
                channels.append(f"{matched_name},{full_url}${ip_info.get(endpoint, 'æœªçŸ¥')}")
            
            return channels
            
        except Exception as e:
            logging.debug(f"å¤„ç† {endpoint} å¤±è´¥: {e}")
            return []
    
    def check_m3u8_fast(url):
        try:
            result = subprocess.run(
                ["ffprobe", "-v", "quiet", "-t", "2", "-i", url],
                stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=3
            )
            return result.returncode == 0
        except:
            return False
    
    # å¹¶å‘å¤„ç†
    endpoints = list(ip_info.keys())
    with concurrent.futures.ThreadPoolExecutor(max_workers=CONFIG["MAX_WORKERS"]) as executor:
        futures = [executor.submit(process_ip, ep) for ep in endpoints]
        for future in concurrent.futures.as_completed(futures):
            all_channels.extend(future.result())
    
    # ç”Ÿæˆæ ‡å‡†M3Uæ ¼å¼
    beijing_time = datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%d %H:%M:%S")
    
    with Path(CONFIG["IPTV_FILE"]).open("w", encoding='utf-8') as f:
        f.write("#EXTM3U\n")
        f.write(f'#PLAYLIST: {beijing_time} | æ€»è®¡: {len(all_channels)} æµ\n\n')
        
        for category, ch_list in CHANNEL_CATEGORIES.items():
            f.write(f"#EXTINF:-1 group-title=\"{category}\"\n")
            category_channels = [
                line for line in all_channels 
                if line.split(",", 1)[0] in ch_list
            ]
            for line in sorted(category_channels):
                name_url, location = line.rsplit("$", 1)
                name, url = name_url.split(",", 1)
                f.write(f'#EXTINF:-1 tvg-name="{name}",{name}\n{url}\n')
            f.write("\n")
    
    unique_channels = len(set(line.split(",", 1)[0] for line in all_channels))
    logging.info(f"ðŸŽ‰ **IPTVç”Ÿæˆå®Œæˆ**ï¼å”¯ä¸€é¢‘é“: {unique_channels}/40 | æ€»æµ: {len(all_channels)}")

# ===============================
# ðŸ“¤ **æ™ºèƒ½GitæŽ¨é€**
def smart_git_push():
    ip_files = list(Path(CONFIG["IP_DIR"]).glob("*.txt"))
    iptv_changed = Path(CONFIG["IPTV_FILE"]).exists() and Path(CONFIG["IPTV_FILE"]).stat().st_size > 100
    
    if not ip_files and not iptv_changed:
        logging.info("âš ï¸ æ— æ–°å†…å®¹ï¼Œè·³è¿‡æŽ¨é€")
        return True
    
    commands = [
        'git config user.name "IPTV-Bot"',
        'git config user.email "bot@github.com"',
        'git add .',
        f'git commit -m "ðŸŽ‰ å•æŸ¥è¯¢æ›´æ–° {datetime.now().strftime("%Y-%m-%d %H:%M")} | é¢‘é“:{Path(CONFIG["IPTV_FILE"]).stat().st_size//100 if iptv_changed else 0}" || echo "No changes"',
        'git push'
    ]
    
    for cmd in commands:
        if os.system(cmd) != 0:
            logging.error(f"âŒ Gitå¤±è´¥: {cmd}")
            return False
    
    logging.info("âœ… **GitæŽ¨é€æˆåŠŸ**")
    return True

# ===============================
# ðŸš€ **ä¸»ç¨‹åº**
def run_iptv():
    start_time = time.time()
    counter = Counter(CONFIG["COUNTER_FILE"])
    
    logging.info("ðŸš€ **v2.4å•FOFAæŸ¥è¯¢IPTVå¯åŠ¨**")
    
    # 1. IPé‡‡é›†
    run_count = first_stage(counter)
    save_success, new_count = counter.increment()
    
    # 2. IPTVç”Ÿæˆï¼ˆæ¯2æ¬¡ï¼‰
    if new_count % 2 == 0:
        generate_iptv()
    
    # 3. GitæŽ¨é€
    smart_git_push()
    
    elapsed = time.time() - start_time
    logging.info(f"âœ… **ä»»åŠ¡å®Œæˆ**ï¼è€—æ—¶: {elapsed:.1f}s | è½®æ¬¡: {new_count}")

# ===============================
# â° **è°ƒåº¦å™¨**
def start_scheduler():
    logging.info("â° **è°ƒåº¦å¯åŠ¨**ï¼š13:00 + 19:00 + æ¯2å°æ—¶")
    for time_str in CONFIG["SCHEDULE_TIMES"]:
        schedule.every().day.at(time_str).do(run_iptv)
    schedule.every(2).hours.do(run_iptv)
    
    while True:
        schedule.run_pending()
        time.sleep(60)

# ===============================
# å…¥å£
if __name__ == "__main__":
    setup_logging()
    
    if len(sys.argv) > 1 and sys.argv[1] == "--scheduler":
        start_scheduler()
    else:
        run_iptv()
